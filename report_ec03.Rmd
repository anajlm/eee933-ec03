---
title: 'Estudo de Caso 3 - Comparação de desempenho de duas configurações de um algoritmo de otimização'
author: "Ana Júlia de Lima Martins, Antônio Carlos da Anunciação, Melchior Augusto Syrio de Melo"
date: "16 de dezembro de 2024"
output:
  pdf_document:
    fig_caption: yes
  html_document:
    df_print: paged
---

```{r setup,results='hide',warning=FALSE,echo=FALSE}
# A few initial definitions just to make sure all required packages are installed. Change as needed.
# NOTE: It may echo some weird messages to the PDF on the first compile (package installation messages). Run twice and the problem will (hopefully) go away.
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
# if (!require(devtools, quietly = TRUE)){
#       install.packages("devtools")
#       }
 if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
      }
# if (!require(GGally, quietly = TRUE)){
#       install.packages("GGally")
#       }
if (!require(dplyr, quietly = TRUE)){
      install.packages("dplyr")
}
if (!require(reshape2, quietly = TRUE)){
      install.packages("reshape2")
}
if (!require(multcomp, quietly = TRUE)){
      install.packages("multcomp")
}
```
## Resumo

Este relatório descreve uma análise estatística do desempenho de duas configurações distintas de um algoritmo de otimização baseado em evolução diferencial (DE). Neste experimento, aplicou-se um Experimento Completamente Aleatorizado com Blocos (RCBD) com o intuito de avaliar o desempenho das duas configurações em diferentes instâncias do problema. A análise teve como objetivo identificar se há diferenças estatisticamente significativas no desempenho médio das configurações, determinando qual delas apresenta o melhor desempenho médio e avaliando a magnitude das diferenças encontradas. Os resultados são apresentados no contexto das questões técnicas de interesse, proporcionando recomendações baseadas nos achados experimentais.

## 1. Design do Experimento

A análise será conduzida a partir de um Experimento Completamente Aleatorizado com Blocos (RCBD), em que as instâncias do algoritmo são consideradas os blocos, e as configurações do algoritmo representam os tratamentos (níveis do fator de interesse). O objetivo é verificar se há diferenças estatisticamente significativas no desempenho médio entre as configurações do algoritmo, levando em conta a variabilidade atribuída às instâncias (blocos).

## 1.1. Hipótese

Para esse experimento, estamos interessados em investigar se há alguma diferença no desempenho médio do algoritmo quando equipado com diferentes configurações, para a classe de problemas de interesse. Portanto, para realizar a análise estatística, estabelecemos as seguintes hipóteses:

- **Hipótese Nula (\(H_0\))**: Não há diferença no desempenho médio entre as configurações, isto é, não existe diferença no tamanho dos efeitos $\tau_i$.

$$\begin{cases} H_0: \tau_i = 0, \ \forall i \in \{1,2,...,a\}\end{cases}$$

- **Hipótese Alternativa (\(H_a\))**: Existe pelo menos uma configuração que apresenta um efeito significativamente diferente de zero, ou seja, com um desempenho superior.

$$\begin{cases} H_1: \exists \ \tau_i \neq 0 \end{cases}$$

Se decidirmos pela rejeição da hipótese nula e as premissas do teste forem validadas, precisaremos determinar qual configuração em termos de desempenho médio. Para responder a essa pergunta, pode-se realizar uma comparação todos contra todos, utilizando o teste de Tukey devido a sua sensibilidade superior ao fazer esse tipo de comparação.

## 1.2. Tamanho amostral

A determinação do tamanho amostral necessário para um RCBD é similar ao procedimento para um CRD.


An important aspect of designing an experiment is to know how many observations are needed to make conclusions of sufficient accuracy and with sufficient confidence. We review what we mean by this statement. The sample size needed depends on lots of things; including what type of experiment is being contemplated, how it will be conducted, resources, and desired sensitivity and confidence.

Sensitivity refers to the difference in means that the experimenter wishes to detect, i.e., sensitive enough to detect important differences in the means.

Generally, increasing the number of replications increases the sensitivity and makes it easier to detect small differences in the means. Both power and the margin of error are a function of n and a function of the error variance. Most of this course is about finding techniques to reduce this unexplained residual error variance, and thereby improving the power of hypothesis tests, and reducing the margin of error in estimation.


### 1.2.1. Estimando o número de instâncias (blocos)

Nesta seção, discutimos a definição do número de repetições necessárias para o experimento, a fim de obter um poder do teste de pelo menos $\pi^* = 0,8$, para detectar diferenças iguais ou superiores a um tamanho de efeito minimamente relevante $d^* = 0,5$, com nível de significância $\alpha = 0,05$.

Sob a hipótese alternativa H1, a estatística $t_0$ segue uma distribuição t não central (Mathews, 2010) com parâmetro de não centralidade dado por:

$$ncp = \frac{(\mu_D - \mu_0) \sqrt{N}}{\hat{\sigma}_{\Phi}} = \frac{\delta \sqrt{N}}{\hat{\sigma}_\Phi} = d \sqrt{N}.$$

Assumindo uma medida de relevância mínima  $d^* = |\delta^*| / \sigma_{\Phi}$, o poder do teste é dado pela integral da distribuição t não central com $ncp^* = d^* \sqrt{N}$ sobre os valores de $t_0$ para os quais a hipótese nula $H_0$ é rejeitada.

O tamanho da amostra para este teste pode ser calculado como o menor inteiro tal que a potência $\pi^*$ é igual ou maior que a potência desejada. No caso da hipótese alternativa unilateral, temos que:


```{r blocos,message=FALSE}
d = 0.5        # Mínima diferença de importância prática (padronizada)
alpha <- 0.05  # Nível de significância
p <- 1 - alpha # Nível de confiança

n <- 2
power <- 0
while (power < 0.8)
{
  df <- n - 1         # n - 1 graus de liberdade
  ncp <- d * sqrt(n)  # Non-centrality parameter
  
  power <- pt(qt(p,df), df, ncp=ncp, lower.tail=FALSE)
  n <- n + 1
}
n
power
```


### 1.2.2. Estimando o número de repetições por bloco

Para calcular o número de repetições necessário por bloco, podemos utilizar a fórmula clássica da estatística para o tamanho de amostra em estimativas de média

he proposed strategy to calculate the number of runs of each algorithm ai on a given
instance γ j , (i.e., the number of repetitions, n i j ) consists in

Any of the techniques discussed in Section 3.7 for selecting the number of repli-
cates to run in a completely randomized single-factor experiment may be applied directly to
the RCBD.

A variabilidade intra-grupo, necessária para calcular o tamanho amostral necessário, corresponde a variância residual estimada, i.e., a variabilidade não explicada pelo fator experimental e pelo fator bloqueado. Essa variabilidade pode ser estimada a partir de um estudo piloto ou informações de estudos passados.

```{r repeticoes,message=FALSE}
# Carregar a tabela de resultados
estudo_piloto <- read.csv("estudo_piloto.csv")

# Criar um dicionário (ou lista) para armazenar os resultados
estatisticas_piloto <- list()

# Obter todas as dimensões únicas
dimensoes <- unique(estudo_piloto$Dimensao)

# Calcular variância e desvio padrão para cada dimensão
for (dim in dimensoes) {
  # Filtrar os dados para a dimensão atual
  dados_dimensao <- subset(estudo_piloto, Dimensao == dim)
  
  # Calcular variância e desvio padrão de Fbest
  variancia <- var(dados_dimensao$Fbest)
  desvio_padrao <- sd(dados_dimensao$Fbest)
  
  # Salvar no dicionário (como uma lista com os dois valores)
  estatisticas_piloto[[as.character(dim)]] <- list(
    Variancia = variancia,
    DesvioPadrao = desvio_padrao
  )
}

estatisticas_piloto_df <- data.frame(
  Dimensao = as.numeric(names(estatisticas_piloto)),
  Variancia = sapply(estatisticas_piloto, function(x) x$Variancia),
  DesvioPadrao = sapply(estatisticas_piloto, function(x) x$DesvioPadrao)
)
```


Now we can use the OC curves exactly as in Example 3.10. Suppose we try n  4 repli-
cates. This results in  2  1.125(4)  4.5,   2.12, and 4(3)  12 degrees of freedom for
error. From the OC curve, we ﬁnd that the power is approximately 0.65. For n  5 replicates,
we have  2  5.625,   2.37, and 4(4)  16 degrees of freedom for error. From the OC
curve, the power is approximately 0.8. For n  6 replicates, we have  2  6.75,   2.60,
and 4(5)  20 degrees of freedom for error. From the OC curve, the power exceeds 0.90, so
n  6 replicates are required.

```{r repeticoes2,message=FALSE}
alpha <- 0.05 # nível de significância
d <- 0.5
a <- 2 # Niveis do fator

# Dataframe para armazenar os resultados
repeticoes <- data.frame(
  Dimensao = integer(),
  Repeticoes = integer()
)

for (dim in dimensoes) {
  # Calcula n para cada dimensão para atingir poder ≥ 0.95
  print(dim)
  n <- 2
  power <- 0
  sd <- estatisticas_piloto_df$DesvioPadrao[estatisticas_piloto_df$Dimensao == dim]
  print(sd)
  D <- d * sd
  print(D)
  
  while (power < 0.8)
  {
    df1 <- a - 1 # Graus de liberdade do numerador
    df2 <- a * (n - 1) # Graus de liberdade do denominador
    #ncp <- (n * D^2) / (2 * sd^2) # Non-centrality parameter
    estudo_piloto
    # Calcular as médias observadas para a dimensão atual
    mu_config1 <- mean(estudo_piloto$Fbest[estudo_piloto$Dimensao == dim & 
                                           estudo_piloto$Configuracao == "Config1"])
    mu_config2 <- mean(estudo_piloto$Fbest[estudo_piloto$Dimensao == dim & 
                                           estudo_piloto$Configuracao == "Config2"])
  
    # Estimação da média geral e do desvio padrão
    mu <- mean(c(mu_config1, mu_config2))  # Média geral
    
    # Calcula o NCP
    ncp <- (n*((mu_config1 - mu)^2 + (mu_config2 - mu)^2)) / (2 * (sd^2))
    print(ncp)
    
    F.crit <- qf(1 - alpha, df1, df2, lower.tail = FALSE)
    print(F.crit)
    
    power <- pf(F.crit, df1, df2, ncp, lower.tail = FALSE)
    print(power)
    n = n + 1
  }
  
  # Armazena os resultados no dataframe
  repeticoes <- rbind(repeticoes, data.frame(Dimensao = dim, Repeticoes = n))
}
```

<!-- ### 2. Descrição do conjunto de dados -->

<!-- Os dados utilizados neste estudo são referentes aos preços de fechamento de cinco ações, extraídos de um arquivo CSV. Cada arquivo contém 36 linhas e 5 colunas, onde: -->

<!-- - Cada linha representa o preço de fechamento mensal das ações, com a linha 1 correspondendo ao mês mais recente e a linha 36 ao mês mais distante. -->
<!-- - Cada coluna representa uma das cinco ações analisadas. -->
<!-- - O conteúdo da posição (i, j) refere-se ao preço de fechamento da ação j no mês i. -->

<!-- Com base nesse conjunto de dados, foi calculado o retorno mensal de cada ação utilizando a fórmula: -->

<!-- \[ -->
<!-- \text{Retorno} = \frac{\text{Preço no mês atual} - \text{Preço no mês anterior}}{\text{Preço no mês anterior}} -->
<!-- \] -->

<!-- O primeiro mês de cada coluna foi descartado, pois não há um valor anterior para o cálculo do retorno. O processo resultou em uma tabela com os retornos mensais das cinco ações. -->


<!-- ```{r loaddata,message=FALSE} -->
<!-- # Lê o arquivo CSV com os preços de fechamento das ações -->
<!-- precos <- read.csv("DadosAcoesGrupoH.csv", header=FALSE) -->
<!-- colnames(precos) <- paste0("Acao_", 1:5) -->

<!-- # Calcula o retorno mensal de cada ação -->
<!-- # Retorno mensal = (Preço atual - Preço anterior) / Preço anterior -->
<!-- retornos <- precos -->
<!-- for (j in 1:ncol(precos)) { -->
<!--   for (i in 1:(nrow(precos)-1)) { -->
<!--     retornos[i, j] <- ((precos[i, j] - precos[i+1, j])) / precos[i+1, j] -->
<!--   } -->
<!-- } -->

<!-- # Remove a ultima linha, referente ao primeiro mês -->
<!-- retornos <- retornos[-36, ] -->

<!-- # Transforma os dados para visualização -->
<!-- retornos_melt <- melt(retornos, variable.name = "Acoes", value.name = "Retorno") -->
<!-- ``` -->


<!-- ## 3. Análise Exploratória -->

<!-- Antes de realizar os testes de hipótese, foi realizada uma análise exploratória para obter uma visão geral dos dados. A Figura @ref(fig:boxplot) fornece um boxplot para comparar as distribuições dos retornos das ações. -->

<!-- ```{r boxplot,fig.width=8,echo=TRUE,message=FALSE,fig.cap="Retorno das Ações (dados originais + boxplots)"} -->

<!-- # Boxplot dos retornos -->
<!-- ggplot(retornos_melt, -->
<!--        aes(x = Acoes, y = Retorno, fill = Acoes)) + -->
<!--     geom_boxplot() + -->
<!--     geom_point() + -->
<!--     ggtitle("Retorno das Ações", -->
<!--             "(dados originais + boxplots)") + -->
<!--     theme(legend.position = "none") -->
<!-- ``` -->

<!-- A análise gráfica indica que a Ação 1 aparenta apresentar o maior retorno médio entre as ações analisadas. -->


<!-- ## 4. Análise Estatística -->

<!-- Para validar nossas observações iniciais, realizamos um teste ANOVA para avaliar as diferenças nos retornos das ações. -->

<!-- ```{r fitmodel,results='hold'} -->
<!-- retornos_melt$Acoes <- as.factor(retornos_melt$Acoes) -->
<!-- model <- aov(Retorno ~ Acoes, data = retornos_melt) -->
<!-- summary(model) -->
<!-- ``` -->

<!-- Como resultado do teste, obteve-se uma estatística F = 34,45 e um p-valor < 2e-16.  -->

<!-- Diante do resultado do teste ANOVA, podemos rejeitar, com nível de significância $\alpha = 0,05$, a hipótese nula de que as médias de retorno das cinco ações são iguais. -->

<!-- Esse resultado indica que nem todas as ações têm retornos médios semelhantes e, para identificar quais ações possuem maior retorno médio, realizamos um teste de Tukey. Os resultados do teste de Turkey são mostrados na Figura @ref{fig:turkey}. -->


<!-- ```{r turkey,results='hold',fig.width=8,echo=TRUE,message=FALSE,fig.cap="Comparações múltiplas - Turkey"} -->
<!-- # Comparações múltiplas -->
<!-- library(multcomp) -->

<!-- mc1    <- glht(model,  -->
<!--                linfct = mcp(Acoes = "Tukey")) -->
<!-- summary(mc1) -->
<!-- mc1_CI <- confint(mc1, level = 0.95) -->

<!-- par(mar = c(5, 10, 4, 2)) # margens -->
<!-- plot(mc1_CI,  -->
<!--      xlab       = "Retornos", -->
<!--      cex.axis   = 1.2, -->
<!--      cex        = 2, -->
<!--      main = "Comparações Múltiplas - Tukey") -->
<!-- ``` -->

<!-- As comparações mais significativas são entre a Ação 2 e as Ações 1, 3, 4 e 5, todas com p-valor < 0,001, indicando que essas ações têm médias de retorno significativamente diferentes. As Ações 1, 3, 4 e 5, por sua vez, apresentam pelo menos uma diferença não significativa quando comparadas entre si. -->

<!-- Confirmando a suspeita inicial, o teste de Tukey indica que a Ação 2 tem o maior retorno médio entre as ações analisadas, visto que as comparações entre a Ação 2 e as outras ações todas mostram diferenças significativas. -->

<!-- ### 5. Verificação das Premissas do Modelo -->
<!-- The assumptions of your test should also be validated, and possible effects of violations should also be explored. -->
<!-- ```{r shapiro,fig.width=8,echo=TRUE,message=FALSE, fig.cap = "Teste de Shapiro-Wilk"} -->
<!-- # Check normality -->
<!-- shapiro.test(retornos_melt) -->

<!-- library(car) -->
<!-- # png(filename = "../figs/paperqq.png", -->
<!-- #     width = 600, height = 600,  -->
<!-- #     bg = "transparent") -->

<!-- qqPlot(retornos_melt,  -->
<!--        pch = 16,  -->
<!--        lwd = 3,  -->
<!--        cex = 2,  -->
<!--        las = 1) -->
<!-- # dev.off() -->

<!-- ``` -->

<!-- # Check homoscedasticity -->
<!-- fligner.test(Retorno ~ Acoes, -->
<!--              data = retornos_melt) -->

<!-- # png(filename = "../figs/papervar.png", -->
<!-- #     width = 600, height = 600,  -->
<!-- #     bg = "transparent") -->
<!-- plot(x    = my.model$fitted.values, -->
<!--      y    = my.model$residuals, -->
<!--      cex  = 2, -->
<!--      las  = 1, -->
<!--      pch  = 16, -->
<!--      xlab = "Fitted values", -->
<!--      ylab = "Residuals") -->
<!-- grid(nx = NULL, ny = NULL,  -->
<!--      lwd = 2, col = "#44444422") -->
<!-- # dev.off() -->
<!-- ``` -->

<!-- ### 6. Conclusões e Recomendações -->
<!-- The discussion of your results, and the scientific/technical meaning of the effects detected, should be placed here. Always be sure to tie your results back to the original question of interest! -->

<!-- ### 7. Atividades Específicas -->

<!-- - Ana Julia: Design do experimento, análise estatística, análise exploratória e descrição do conjunto de dados (redação e código)  -->
<!-- - Antônio:  -->
<!-- - Melchior: -->